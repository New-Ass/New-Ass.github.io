<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>千里之行，始于足下。python 爬虫 requestes模块（2）</title>
      <link href="/2022/11/19/%E5%8D%83%E9%87%8C%E4%B9%8B%E8%A1%8C%EF%BC%8C%E5%A7%8B%E4%BA%8E%E8%B6%B3%E4%B8%8B%E3%80%82python%20%E7%88%AC%E8%99%AB%20requestes%E6%A8%A1%E5%9D%97%EF%BC%882%EF%BC%89/"/>
      <url>/2022/11/19/%E5%8D%83%E9%87%8C%E4%B9%8B%E8%A1%8C%EF%BC%8C%E5%A7%8B%E4%BA%8E%E8%B6%B3%E4%B8%8B%E3%80%82python%20%E7%88%AC%E8%99%AB%20requestes%E6%A8%A1%E5%9D%97%EF%BC%882%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h1 id="简易网页搜集器"><a href="#简易网页搜集器" class="headerlink" title="简易网页搜集器"></a>简易网页搜集器</h1><p>前面我们已经学会了简单爬取浏览器页面的爬虫。但事实上我们的需求当然不是爬取搜狗首页或是B站首页这么简单，再不济，我们都希望可以爬取某个特定的有信息的页面。</p><p>不知道在学会了爬取之后，你有没有跟我一样试着去爬取一些搜索页面，比如说百度。像这样的页面</p><p><img src="https://img-blog.csdnimg.cn/20210415104803318.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70" alt="要爬取的网页"></p><p>注意我红笔划的部分，这是我打开的网页。现在我希望能爬取这一页的数据，按我们前面学的代码，应该是这样写的：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> requests<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># 指定URL</span>    url <span class="token operator">=</span> <span class="token string">"https://www.baidu.com/s?ie=utf-8&amp;f=8&amp;rsv_bp=1&amp;rsv_idx=2&amp;tn=93923645_hao_pg&amp;wd=%E5%A5%A5%E7%89%B9%E6%9B%BC&amp;rsv_spt=1&amp;oq=%25E7%2588%25AC%25E5%258F%2596%25E7%2599%25BE%25E5%25BA%25A6%25E9%25A6%2596%25E9%25A1%25B5&amp;rsv_pq=b233dcfd0002d2d8&amp;rsv_t=ccdbEuqbJfqtjnkFvevj%2BfxQ0Sj2UP88ixXHTNUNsmTa9yWEWTUEgxTta9r%2Fj3mXxDs%2BT1SU&amp;rqlang=cn&amp;rsv_dl=tb&amp;rsv_enter=1&amp;rsv_sug3=8&amp;rsv_sug1=5&amp;rsv_sug7=100&amp;rsv_sug2=0&amp;rsv_btype=t&amp;inputT=1424&amp;rsv_sug4=1424"</span>    <span class="token comment" spellcheck="true"># 发送请求</span>    response <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 获取数据</span>    page_text <span class="token operator">=</span> response<span class="token punctuation">.</span>text    <span class="token comment" spellcheck="true"># 存储</span>    <span class="token keyword">with</span> open<span class="token punctuation">(</span><span class="token string">"./奥特曼.html"</span><span class="token punctuation">,</span> <span class="token string">"w"</span><span class="token punctuation">,</span> encoding <span class="token operator">=</span> <span class="token string">"utf-8"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> fp<span class="token punctuation">:</span>        fp<span class="token punctuation">.</span>write<span class="token punctuation">(</span>page_text<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"爬取成功！！！"</span><span class="token punctuation">)</span></code></pre><p>然而打开我们保存的文件，发现结果跟我们想的不太一样<br><img src="https://img-blog.csdnimg.cn/20210415110105396.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70"><br>我们发现我们保存的文件是一个空白的页面，这是为什么呢？</p><p>其实上我们把网址改成搜狗的可能或更直观一些（不知道为什么我这边的搜狗总是打不开，所以就用百度做例子，可以自己写写有关搜狗搜索的代码），同样的代码改成搜狗的网址结果是这样的</p><p><img src="https://img-blog.csdnimg.cn/20210415110721166.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70"><br>我们发现其中有句话是 “ 网络中存在异常访问 ”，那么这句话是什么意思呢？这句话的意思就是说，搜狗或是百度注意到发送请求的是爬虫程序，而不是人工操作。</p><p>那么这其中的原理又是什么呢？简单来说，就是程序访问和我们使用浏览器访问是有区别的，被请求的服务器都是靠 user-agent 来判断访问者的身份，如果是浏览器就接受请求，否则就拒绝。这就是一个很常见的反爬机制。</p><p>那是不是我们就没有办法呢？非也~所谓魔高一尺，道高一丈。既然要识别 user-agent ，那么我们就让爬虫模拟 user-agent 好了。</p><p>在 python 中模拟输入数据或是 user-agent ，我们一般用字典<br>就这样子写：</p><pre class=" language-python"><code class="language-python">header <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>    <span class="token string">"user-agent"</span><span class="token punctuation">:</span> <span class="token string">""</span> <span class="token comment" spellcheck="true"># user-agent 的值 是一个长字符串</span>    <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span></code></pre><p>那么  user-agent 的值又是怎么得到的呢？<br>    1. 打开任意网页，右键点击，选择“检查”<br><img src="https://img-blog.csdnimg.cn/20210415112140584.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70"><br>    2. 选择“ Network ”（谷歌浏览器）（如果是中文，就选择 “网络” 这一项）<br><img src="https://img-blog.csdnimg.cn/20210415112339671.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70"><br>    3. 如果发现点开是空白的，像这样，那就刷新网页<br>    <img src="https://img-blog.csdnimg.cn/2021041511261560.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70"><br>    刷新后是这样的：<br>    <img src="https://img-blog.csdnimg.cn/20210415112717305.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70"><br>然后随机选择红笔圈起来的一项，我们会看到这样的东西，然后在里面找到“user-agent”，把它的值复制下来就行了<br><img src="https://img-blog.csdnimg.cn/20210415113039196.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70"><br>有了 “user-agent”， 我们在重新写我们的爬取网页的代码，就可以了</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> requests<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># 指定URL</span>    url <span class="token operator">=</span> <span class="token string">"https://www.baidu.com/s?ie=utf-8&amp;f=8&amp;rsv_bp=1&amp;rsv_idx=2&amp;tn=93923645_hao_pg&amp;wd=%E5%A5%A5%E7%89%B9%E6%9B%BC&amp;rsv_spt=1&amp;oq=%25E7%2588%25AC%25E5%258F%2596%25E7%2599%25BE%25E5%25BA%25A6%25E9%25A6%2596%25E9%25A1%25B5&amp;rsv_pq=b233dcfd0002d2d8&amp;rsv_t=ccdbEuqbJfqtjnkFvevj%2BfxQ0Sj2UP88ixXHTNUNsmTa9yWEWTUEgxTta9r%2Fj3mXxDs%2BT1SU&amp;rqlang=cn&amp;rsv_dl=tb&amp;rsv_enter=1&amp;rsv_sug3=8&amp;rsv_sug1=5&amp;rsv_sug7=100&amp;rsv_sug2=0&amp;rsv_btype=t&amp;inputT=1424&amp;rsv_sug4=1424"</span>    <span class="token comment" spellcheck="true"># 模拟 “user-agent”，即 UA伪装</span>    header <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>        <span class="token string">"user-agent"</span> <span class="token punctuation">:</span> <span class="token string">""</span> <span class="token comment" spellcheck="true"># 复制的 user-agent 的值</span>        <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span>    <span class="token comment" spellcheck="true"># 发送请求</span>    response <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">,</span> headers <span class="token operator">=</span> header<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 获取数据</span>    page_text <span class="token operator">=</span> response<span class="token punctuation">.</span>text    <span class="token comment" spellcheck="true"># 存储</span>    <span class="token keyword">with</span> open<span class="token punctuation">(</span><span class="token string">"./奥特曼(UA伪装).html"</span><span class="token punctuation">,</span> <span class="token string">"w"</span><span class="token punctuation">,</span> encoding <span class="token operator">=</span> <span class="token string">"utf-8"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> fp<span class="token punctuation">:</span>        fp<span class="token punctuation">.</span>write<span class="token punctuation">(</span>page_text<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"爬取成功！！！"</span><span class="token punctuation">)</span></code></pre><p>再次运行，然后打开文件<br><img src="https://img-blog.csdnimg.cn/20210415113826866.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70"><br>这次成功了，说明我们的爬虫程序完美地骗过了服务器</p>]]></content>
      
      
      <categories>
          
          <category> 爬虫 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 爬虫 </tag>
            
            <tag> request </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>千里之行，始于足下。python 爬虫 requestes模块（1）</title>
      <link href="/2022/11/19/%E5%8D%83%E9%87%8C%E4%B9%8B%E8%A1%8C%EF%BC%8C%E5%A7%8B%E4%BA%8E%E8%B6%B3%E4%B8%8B%E3%80%82python%20%E7%88%AC%E8%99%AB%20requestes%E6%A8%A1%E5%9D%97%EF%BC%881%EF%BC%89/"/>
      <url>/2022/11/19/%E5%8D%83%E9%87%8C%E4%B9%8B%E8%A1%8C%EF%BC%8C%E5%A7%8B%E4%BA%8E%E8%B6%B3%E4%B8%8B%E3%80%82python%20%E7%88%AC%E8%99%AB%20requestes%E6%A8%A1%E5%9D%97%EF%BC%881%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h1 id="爬虫的流程："><a href="#爬虫的流程：" class="headerlink" title="爬虫的流程："></a>爬虫的流程：</h1><p>在开始学习爬虫，我们必须了解爬虫的流程框架。在我看来爬虫的流程大概就是三步，即不论我们爬取的是什么数据，总是可以把爬虫的流程归纳总结为这三步：</p><ol><li>指定 url， 可以简单的理解为指定要爬取的网址</li><li>发送请求。requests 模块的请求一般为 get 和 post</li><li>将爬取的数据存储</li></ol><h1 id="requests-模块的下载导入："><a href="#requests-模块的下载导入：" class="headerlink" title="requests 模块的下载导入："></a>requests 模块的下载导入：</h1><p>因为 requests 模块属于外部库，所以需要我们自己导入库</p><p>导入的步骤：</p><ol><li>右键Windows图标</li><li>点击“运行”</li><li>输入“cmd”打开命令面板</li><li>输入“pip install requests”,等待下载完成</li></ol><p>如图：</p><p><img src="https://img-blog.csdnimg.cn/20210413165648257.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_1,color_FFFFFF,t_70"></p><p><img src="https://img-blog.csdnimg.cn/20210413165904237.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70" alt="打开cmd"></p><p><img src="https://img-blog.csdnimg.cn/20210413165910162.png" alt="下载 requests 模块 "></p><p>如果还是下载失败，我的建议是”百度一下，你就知道“（我也是边学边写，是在是水平有限）</p><p>欧克，既然导入成功后我们就简单的来爬取一下搜狗的首页吧！<br>代码如下：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> requests<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># 指定url</span>    url <span class="token operator">=</span> <span class="token string">"https://www.sougou.com/"</span>    <span class="token comment" spellcheck="true"># 发起请求</span>    <span class="token comment" spellcheck="true"># get方法会返回一个响应数据</span>    response <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 获取响应数据</span>    page_txt <span class="token operator">=</span> response<span class="token punctuation">.</span>text <span class="token comment" spellcheck="true"># text返回一个字符串的响应数据</span>    <span class="token comment" spellcheck="true"># print(page_txt)</span>    <span class="token comment" spellcheck="true"># 存储</span>    <span class="token keyword">with</span> open<span class="token punctuation">(</span><span class="token string">"./sougou.html"</span><span class="token punctuation">,</span> <span class="token string">"w"</span><span class="token punctuation">,</span> encoding <span class="token operator">=</span> <span class="token string">"utf-8"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> fp<span class="token punctuation">:</span>        fp<span class="token punctuation">.</span>write<span class="token punctuation">(</span>page_txt<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"爬取数据结束！！！"</span><span class="token punctuation">)</span></code></pre><p>我们打开保存的文件，如图<br><img src="https://img-blog.csdnimg.cn/2021041317282155.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70" alt="成功保存的网页"></p>]]></content>
      
      
      <categories>
          
          <category> 爬虫 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 爬虫 </tag>
            
            <tag> request </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2022/11/18/hello-world/"/>
      <url>/2022/11/18/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre class=" language-bash"><code class="language-bash">$ hexo new <span class="token string">"My New Post"</span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre class=" language-bash"><code class="language-bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre class=" language-bash"><code class="language-bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre class=" language-bash"><code class="language-bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      <categories>
          
          <category> hexo </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
