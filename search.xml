<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>千里之行，始于足下。python 爬虫 requestes模块（6）</title>
      <link href="/2022/11/20/qian-li-zhi-xing-shi-yu-zu-xia-python-pa-chong-requestes-mo-kuai-6/"/>
      <url>/2022/11/20/qian-li-zhi-xing-shi-yu-zu-xia-python-pa-chong-requestes-mo-kuai-6/</url>
      
        <content type="html"><![CDATA[<h1 id="药监局爬取"><a href="#药监局爬取" class="headerlink" title="药监局爬取"></a>药监局爬取</h1><p>是不是在看到 “ 药监局 ” 这三个字的时候，突然想到爬虫可能会进局子的事实？ 说到局子，我突然想到另一件事，因为前面写的是很基础的代码，没有代理池，所以在写的时候，特别是爬取翻页的时候，尽量减少爬取的页数，不然，额，后果自负。</p><p>开个玩笑，没什么大问题的，就是很有可能自己的 IP 会被对面拉入黑名单（目前学的代码而言）</p><p>欧克，言归正传，让我们回到药监局的爬取上吧。如果不出意外的话，这是 requests 模块的最后练习了，结束之后就是激动人心的数据解析了。</p><p>先说说药监局网站，我不清楚是因为我用的是学校局域网的原因，还是药监局网站本身的数据维护更新原因，我这边晚上八点半之后就打开不了药监局网站了。</p><p>闲话少说（其实说了很多），我们先打开药监局网站（<a href="http://scxk.nmpa.gov.cn:81/xk/%EF%BC%89%EF%BC%8C%E4%B8%80%E6%8E%A2%E7%A9%B6%E7%AB%9F%E3%80%82">http://scxk.nmpa.gov.cn:81/xk/），一探究竟。</a><br><img src="https://img-blog.csdnimg.cn/20210420150643122.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70"><br>当我们随便点击一家企业时，得到的界面如下：</p><p><img src="https://img-blog.csdnimg.cn/20210420150720521.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70"><br>而这些企业具体信息是我们今天要爬取的对象数据。</p><p>首先我们来爬取药监局的首页数据。<br>代码如下：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> requests<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># UA 伪装</span>    header <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token string">"user-agent"</span><span class="token punctuation">:</span> <span class="token string">"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.72 Safari/537.36"</span>        <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true"># 指定 URL</span>    url <span class="token operator">=</span> <span class="token string">"http://scxk.nmpa.gov.cn:81/xk/"</span>    <span class="token comment" spellcheck="true"># 发送请求</span>    page_text <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">,</span> headers <span class="token operator">=</span> header<span class="token punctuation">)</span><span class="token punctuation">.</span>text    <span class="token comment" spellcheck="true"># 保存</span>    <span class="token keyword">with</span> open<span class="token punctuation">(</span><span class="token string">"./药监局.html"</span><span class="token punctuation">,</span> <span class="token string">"w"</span><span class="token punctuation">,</span> encoding <span class="token operator">=</span> <span class="token string">"utf-8"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> fp<span class="token punctuation">:</span>        fp<span class="token punctuation">.</span>write<span class="token punctuation">(</span>page_text<span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"over!!!"</span><span class="token punctuation">)</span></code></pre><p>然后我们打开保存的文件一看。<br><img src="https://img-blog.csdnimg.cn/20210420151921155.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70"><br>唉，为什么，明明已经加载完成了，但我们看不到任何企业的信息？</p><p>别着急，让我们现在回到药监局的首页，打开抓包工具的 “ Network ” 分析一波（当然其实我们可以使用 数据解析 解决这个问题，但实际上我们还没学不是吗？）。欧克，回到抓包工具，点击 response。</p><p><img src="https://img-blog.csdnimg.cn/20210420152351636.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70"><br>然后在按下 “ctrl” + “F”，开始查找</p><p><img src="https://img-blog.csdnimg.cn/20210420152537239.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70"><br>我们发现网页源码上并没有 “海南” ， 但我们的公司名称里却有，这说明，我们对应的 url 并不能获取我们需要的数据，那么这些数据在哪里呢？不知道你们有没有想到我们前面提到过的 AJAX。好吧，既然我们没有别的办法，那就试试喽。</p><p>结果这一看真是不得了。</p><p><img src="https://img-blog.csdnimg.cn/20210420153033526.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70"><br>response 里的 json 不就是我们想要的吗？赶紧兴奋地去在线解析一下<br><img src="https://img-blog.csdnimg.cn/20210420153306674.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70"><br>我们会发现这些数据里面的 ID 特别显眼，然后再回到我们公司的具体信息的页面，一看，我的天呀，这是什么啊。<br><img src="https://img-blog.csdnimg.cn/20210420153703282.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70"><br>这不就是我们要的 url 里的动态部分吗？别太激动了，试验一下。</p><p><img src="https://img-blog.csdnimg.cn/20210420153841806.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70"><br>一验证，发现果然如此，这不得仰天长啸一翻，天不亡我。</p><p>好了，既然得到了这些信息，我们是不是就可以写代码了吗？</p><p>当然你要写没有拦你，但你打开一看自己得到的数据或是网页，就会发现，结果和前面一样，没有任何数据。然后我们再一次重复上面的数据就会发现数据还是被保存在 XHR 的请求中，是不是特别想说一句 “ 禁止套娃 ”？</p><p>不管有多少脏话要骂，还是要写代码，唉，要不边写边骂？</p><p>代码如下：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> requests<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># UA 伪装</span>    header <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token string">"user-agent"</span><span class="token punctuation">:</span> <span class="token string">"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.72 Safari/537.36"</span>        <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true"># 指定 XHR 的 url</span>    url <span class="token operator">=</span> <span class="token string">"http://scxk.nmpa.gov.cn:81/xk/itownet/portalAction.do?method=getXkzsList"</span>    <span class="token comment" spellcheck="true"># data</span>    data <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token string">"on"</span><span class="token punctuation">:</span> <span class="token string">"true"</span><span class="token punctuation">,</span>        <span class="token string">"page"</span><span class="token punctuation">:</span> <span class="token string">"1"</span><span class="token punctuation">,</span>        <span class="token string">"pageSize"</span><span class="token punctuation">:</span> <span class="token string">"15"</span><span class="token punctuation">,</span>        <span class="token string">"productName"</span><span class="token punctuation">:</span> <span class="token string">""</span><span class="token punctuation">,</span>         <span class="token string">"conditionType"</span><span class="token punctuation">:</span> <span class="token string">"1"</span><span class="token punctuation">,</span>        <span class="token string">"applyname"</span><span class="token punctuation">:</span> <span class="token string">""</span><span class="token punctuation">,</span>        <span class="token string">"applysn"</span><span class="token punctuation">:</span> <span class="token string">""</span>        <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true"># 存储最后的 ID 数据</span>    id_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> page <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment" spellcheck="true"># 翻两页</span>        data<span class="token punctuation">[</span><span class="token string">"page"</span><span class="token punctuation">]</span> <span class="token operator">=</span> str<span class="token punctuation">(</span>page<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 发送请求命令，获取 json 数据</span>        data_json <span class="token operator">=</span> requests<span class="token punctuation">.</span>post<span class="token punctuation">(</span>url<span class="token punctuation">,</span> data <span class="token operator">=</span> data<span class="token punctuation">,</span> headers <span class="token operator">=</span> header<span class="token punctuation">)</span><span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 分析一下 json 数据的结构</span>        data_list <span class="token operator">=</span> data_json<span class="token punctuation">[</span><span class="token string">"list"</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> data_list<span class="token punctuation">:</span>            id_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>i<span class="token punctuation">[</span><span class="token string">"ID"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 公司具体信息网页的 XHR 中的 url</span>    new_url <span class="token operator">=</span> <span class="token string">"http://scxk.nmpa.gov.cn:81/xk/itownet/portalAction.do?method=getXkzsById"</span>    data <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token string">"id"</span><span class="token punctuation">:</span> <span class="token string">"5eb10afc74a2462c8e86652ec8d90a48"</span><span class="token punctuation">}</span>    <span class="token keyword">for</span> ID <span class="token keyword">in</span> id_list<span class="token punctuation">:</span>        data<span class="token punctuation">[</span><span class="token string">"id"</span><span class="token punctuation">]</span> <span class="token operator">=</span> ID        <span class="token comment" spellcheck="true"># 发送请求</span>        response <span class="token operator">=</span> requests<span class="token punctuation">.</span>post<span class="token punctuation">(</span>new_url<span class="token punctuation">,</span> data <span class="token operator">=</span> data<span class="token punctuation">,</span> headers <span class="token operator">=</span> header<span class="token punctuation">)</span><span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 这是一个json串，我们可以先在线解析，再保存我们想要的东西</span>        name <span class="token operator">=</span> response<span class="token punctuation">[</span><span class="token string">"epsName"</span><span class="token punctuation">]</span>        <span class="token comment" spellcheck="true"># 保存</span>        <span class="token keyword">with</span> open<span class="token punctuation">(</span><span class="token string">".公司信息.text"</span><span class="token punctuation">,</span> <span class="token string">"a"</span><span class="token punctuation">,</span> encoding <span class="token operator">=</span> <span class="token string">"utf-8"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> fp<span class="token punctuation">:</span>            fp<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"公司名称："</span> <span class="token operator">+</span> response<span class="token punctuation">[</span><span class="token string">"epsName"</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token string">"\n"</span> <span class="token operator">+</span> <span class="token string">"公司地址："</span> <span class="token operator">+</span> response<span class="token punctuation">[</span><span class="token string">"epsProductAddress"</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token string">"\n"</span> <span class="token operator">+</span> <span class="token string">"法定代表人："</span> <span class="token operator">+</span> response<span class="token punctuation">[</span><span class="token string">"legalPerson"</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token string">"\n"</span> <span class="token operator">+</span> <span class="token string">"\n"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 提示</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>name <span class="token operator">+</span> <span class="token string">"的信息下载完成！！！"</span><span class="token punctuation">)</span></code></pre><p>我们运行一下程序，结果如下：<br><img src="https://img-blog.csdnimg.cn/20210420190105233.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70"></p><p>打开文件一看<br><img src="https://img-blog.csdnimg.cn/20210420190154657.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70"></p>]]></content>
      
      
      <categories>
          
          <category> 爬虫 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 爬虫 </tag>
            
            <tag> request </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>千里之行，始于足下。python 爬虫 requestes模块（5）</title>
      <link href="/2022/11/20/qian-li-zhi-xing-shi-yu-zu-xia-python-pa-chong-requestes-mo-kuai-5/"/>
      <url>/2022/11/20/qian-li-zhi-xing-shi-yu-zu-xia-python-pa-chong-requestes-mo-kuai-5/</url>
      
        <content type="html"><![CDATA[<h1 id="肯德基餐厅地址查询"><a href="#肯德基餐厅地址查询" class="headerlink" title="肯德基餐厅地址查询"></a>肯德基餐厅地址查询</h1><p>前面我们学习了破解百度翻译，知道了 AJAX 的工作原理和爬取，那么我们今天就来巩固我们的学习成果吧。</p><p>首先我们打开肯德基的官网，点击 “餐厅查询”<br><img src="https://img-blog.csdnimg.cn/20210418212331439.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70"><br>然后是没有地址的网页，然后我们输入地址<br><img src="https://img-blog.csdnimg.cn/20210418212616822.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70"></p><p><img src="https://img-blog.csdnimg.cn/20210418212546441.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70"><br>我们发现不论有没有搜索，网址都没有发生变化，这说明肯德基官网的地址查询是通过 AJAX 实现的，知道了这样一点我们就可以使用抓包工具进行分析了。</p><p>我们可以从抓包工具中找到请求的 url 和相对应的请求命令和数据类型。<br><img src="https://img-blog.csdnimg.cn/20210418214041202.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70"><br><img src="https://img-blog.csdnimg.cn/20210418214055199.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70"><br><img src="https://img-blog.csdnimg.cn/20210418231617567.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70"></p><p>我们发现这是一个 json 串，我们还需要像上次破解百度翻译一样先把 json 串爬取下来，再在线解析吗？答案当然是否定的，我们可以在抓包工具的 response 中得到目前的 json，然后在线解析。</p><p><img src="https://img-blog.csdnimg.cn/20210418213447336.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70"><br><img src="https://img-blog.csdnimg.cn/20210418213609839.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70"></p><p>欧克，那么我就可以开始写爬取肯德基餐厅地址的代码了</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> requests<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># 指定 URL</span>    url <span class="token operator">=</span> <span class="token string">"http://www.kfc.com.cn/kfccda/ashx/GetStoreList.ashx?op=keyword"</span>    <span class="token comment" spellcheck="true"># UA 伪装</span>    header <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token string">"user-agent"</span><span class="token punctuation">:</span> <span class="token string">"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36"</span>        <span class="token punctuation">}</span>        <span class="token comment" spellcheck="true"># 数据</span>    kd <span class="token operator">=</span> input<span class="token punctuation">(</span><span class="token string">"需要查询的地点："</span><span class="token punctuation">)</span>    data <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token string">"cname"</span><span class="token punctuation">:</span> <span class="token string">""</span><span class="token punctuation">,</span>        <span class="token string">"pid"</span><span class="token punctuation">:</span> <span class="token string">""</span><span class="token punctuation">,</span>         <span class="token string">"keyword"</span><span class="token punctuation">:</span> kd <span class="token punctuation">,</span> <span class="token comment" spellcheck="true"># 要搜索的地址</span>        <span class="token string">"pageIndex"</span><span class="token punctuation">:</span> <span class="token string">"1"</span> <span class="token punctuation">,</span> <span class="token comment" spellcheck="true"># 要爬取的网页的页码</span>        <span class="token string">"pageSize"</span><span class="token punctuation">:</span> <span class="token string">"10"</span> <span class="token comment" spellcheck="true"># 每一页的数量</span>        <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true"># 发送请求</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment" spellcheck="true"># 爬取两页</span>        data<span class="token punctuation">[</span><span class="token string">"pageIndex"</span><span class="token punctuation">]</span> <span class="token operator">=</span> str<span class="token punctuation">(</span>i<span class="token punctuation">)</span>        response <span class="token operator">=</span> requests<span class="token punctuation">.</span>post<span class="token punctuation">(</span>url <span class="token operator">=</span> url<span class="token punctuation">,</span> data <span class="token operator">=</span> data<span class="token punctuation">,</span> headers <span class="token operator">=</span> header<span class="token punctuation">)</span><span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token punctuation">)</span>        page <span class="token operator">=</span> response<span class="token punctuation">[</span><span class="token string">"Table1"</span><span class="token punctuation">]</span>        <span class="token comment" spellcheck="true"># 存储</span>        <span class="token keyword">for</span> detail <span class="token keyword">in</span> page<span class="token punctuation">:</span>            <span class="token keyword">with</span> open<span class="token punctuation">(</span><span class="token string">"./肯德基地址.txt"</span><span class="token punctuation">,</span> <span class="token string">"a"</span><span class="token punctuation">,</span> encoding <span class="token operator">=</span> <span class="token string">"utf-8"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> fp<span class="token punctuation">:</span>                fp<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"storeName:"</span> <span class="token operator">+</span> detail<span class="token punctuation">[</span><span class="token string">"storeName"</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token string">"\n"</span> <span class="token operator">+</span> <span class="token string">"addressDetail:"</span> <span class="token operator">+</span> detail<span class="token punctuation">[</span><span class="token string">"addressDetail"</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token string">"\n"</span> <span class="token operator">+</span> <span class="token string">"\n"</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"over!!!"</span><span class="token punctuation">)</span></code></pre><p>打开保存的文件如下</p><p><img src="https://img-blog.csdnimg.cn/20210418231504846.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70"></p><p>说明爬取成功</p>]]></content>
      
      
      <categories>
          
          <category> 爬虫 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 爬虫 </tag>
            
            <tag> request </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>千里之行，始于足下。python 爬虫 requestes模块（4）</title>
      <link href="/2022/11/20/qian-li-zhi-xing-shi-yu-zu-xia-python-pa-chong-requestes-mo-kuai-4/"/>
      <url>/2022/11/20/qian-li-zhi-xing-shi-yu-zu-xia-python-pa-chong-requestes-mo-kuai-4/</url>
      
        <content type="html"><![CDATA[<h1 id="“破解”百度翻译"><a href="#“破解”百度翻译" class="headerlink" title="“破解”百度翻译"></a>“破解”百度翻译</h1><p>翻译是一件麻烦的事情，如果可以写一个爬虫程序直接爬取百度翻译的翻译结果就好了，可当我打开百度翻译的页面，输入要翻译的词时突然发现不管我要翻译什么，网址都没有任何变化，那么百度翻译要怎么爬取呢？</p><p>爬取百度翻译之前，我们先要明白百度翻译是怎么在不改变网址的情况下实现翻译的。百度做到这一点是用 AJAX 实现的，简单地说，AJAX的作用是在不重新加载网页的情况下进行局部的刷新。</p><p>了解了这一点，那么我们要怎么得到 AJAX 工作时请求的URL呢？老规矩，使用抓包工具。步骤如下：</p><ol><li>在 “百度翻译” 页面右键，选择“Notework”</li><li>选择 “ XHR ”</li></ol><p><img src="https://img-blog.csdnimg.cn/2021041717220450.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70"></p><ol start="3"><li>如果画面没有任何数据，可以试着输入要翻译的词，比如说我输入“dog”时，就发生了如下的变化</li></ol><p><img src="https://img-blog.csdnimg.cn/20210417172456378.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70"><br>我们看到此时的 kw 是我要翻译的词，说明这是我们要找的东西。</p><p>（注意：我们发现其中有三个 sug ，我选的只是其中一个。如果我们全都带点开看，就会发现，他们的 kw 分别是：d 和 do。这是因为我打 dog 时一个单词一个单词打的，而 AJAX 是时时刷新。如果输入中文就不会出现这种情况。翻译中文时，我们找的也不是 sug 了，具体是什么，就看哪个包的 data 的值是我们要翻译的词。）</p><p>然后我们在回到上面，找到我们需要指定的 URL 、我们要选择的请求命令以及爬取到的数据的类型。</p><p><img src="https://img-blog.csdnimg.cn/2021041719215232.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70"></p><p>欧克，做到这里我们的前期准备就完成了，下面就可以开始着手写代码了。</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> requests<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># 指定 url</span>    url <span class="token operator">=</span> <span class="token string">"https://fanyi.baidu.com/sug"</span>    <span class="token comment" spellcheck="true"># 要翻译的词</span>    keyword <span class="token operator">=</span> input<span class="token punctuation">(</span><span class="token string">"需要翻译的词："</span><span class="token punctuation">)</span>    data <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token string">"kw"</span><span class="token punctuation">:</span> keyword        <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true"># UA 伪装</span>    header <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token string">"user-agent"</span><span class="token punctuation">:</span> <span class="token string">"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36"</span>        <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true"># 发送请求</span>    response <span class="token operator">=</span> requests<span class="token punctuation">.</span>post<span class="token punctuation">(</span>url <span class="token operator">=</span> url<span class="token punctuation">,</span> data <span class="token operator">=</span> data<span class="token punctuation">,</span> headers <span class="token operator">=</span> header<span class="token punctuation">)</span><span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">)</span></code></pre><p>我们运行程序发现结果是这样的：<br><img src="https://img-blog.csdnimg.cn/2021041719410599.png"><br>因为请求到的数据比较短，所以我们比较容易地看出数据的结构是字典里有列表，列表里又有字典结构。如果比较长，我们可以使用在线 json 转换,转换后的数据是这样的</p><p><img src="https://img-blog.csdnimg.cn/20210417194625764.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70"><br>我们只需要 dog 的释义，所以我们还可以对我们代码进行优化</p><pre class=" language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">[</span><span class="token string">"data"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"v"</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><p>注意：<br>关于 data 的字典，并不是说只需要 “ kw ”: dog, data 的字典里要存储的是抓包工具里 from data 里所有的值，如果没有值，那么相对应的值就是空字符串。</p>]]></content>
      
      
      <categories>
          
          <category> 爬虫 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 爬虫 </tag>
            
            <tag> request </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>千里之行，始于足下。python 爬虫 requestes模块（3）</title>
      <link href="/2022/11/20/qian-li-zhi-xing-shi-yu-zu-xia-python-pa-chong-requestes-mo-kuai-3/"/>
      <url>/2022/11/20/qian-li-zhi-xing-shi-yu-zu-xia-python-pa-chong-requestes-mo-kuai-3/</url>
      
        <content type="html"><![CDATA[<h1 id="简易网页搜集器（2）"><a href="#简易网页搜集器（2）" class="headerlink" title="简易网页搜集器（2）"></a>简易网页搜集器（2）</h1><p>前面我们学会了如何用 UA 伪装骗过服务器爬取我们想要的网页数据，不知道你们会不会和我一样在学会 UA 伪装的兴奋后突然想到另一个问题——就是我们爬取一个页面就要改一次 url 吗？</p><p>答案当然是否定的。</p><p>我们观察下面两个网址<br><img src="https://img-blog.csdnimg.cn/2021041616565422.png"><br><img src="https://img-blog.csdnimg.cn/20210416165736945.png"><br>一个显然易见的区别是我圈起来的部分，即“wd &#x3D; ”<br>那我就怀疑搜索不同的关键词，“wd” 都不同，那么是不是这么一回事呢？我们可以试试。</p><p>结果就像这样<br><img src="https://img-blog.csdnimg.cn/20210416170212646.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70"><br>欧克，这就说明关键在于 “wd”的值，那么我们就可以根据这点写一个动态的URL</p><p>代码如下：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> requests<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># 要搜索的内容</span>    kd <span class="token operator">=</span> input<span class="token punctuation">(</span><span class="token string">"百度一下，你就知道："</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 指定url</span>    url <span class="token operator">=</span> <span class="token string">"https://www.baidu.com/s?"</span>    param <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token string">"wd"</span><span class="token punctuation">:</span> kd        <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true"># UA 伪装</span>    header <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token string">"User-Agent"</span><span class="token punctuation">:</span> <span class="token string">"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36"</span>        <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true"># 发送请求</span>    page_text <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url <span class="token operator">=</span> url<span class="token punctuation">,</span> params <span class="token operator">=</span> param<span class="token punctuation">,</span> headers <span class="token operator">=</span> header<span class="token punctuation">)</span><span class="token punctuation">.</span>text    <span class="token comment" spellcheck="true"># 存储</span>    <span class="token keyword">with</span> open<span class="token punctuation">(</span><span class="token string">"."</span><span class="token operator">+</span>kd<span class="token operator">+</span><span class="token string">".html"</span><span class="token punctuation">,</span> <span class="token string">"w"</span><span class="token punctuation">,</span> encoding <span class="token operator">=</span> <span class="token string">"utf-8"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> fp<span class="token punctuation">:</span>        fp<span class="token punctuation">.</span>write<span class="token punctuation">(</span>page_text<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"爬取数据成功！！！"</span><span class="token punctuation">)</span></code></pre><p>当然，url 还可以写成这样的</p><pre class=" language-python"><code class="language-python">url <span class="token operator">=</span> <span class="token string">"https://www.baidu.com/s?"</span> <span class="token operator">+</span> <span class="token string">"wd="</span> <span class="token operator">+</span> kd</code></pre><p>我们打开保存的文件，看看结果<br><img src="https://img-blog.csdnimg.cn/20210416172140334.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70"><br>这说明我们的代码没有问题，我们可以不改变代码实现关键词搜索爬取网页了</p>]]></content>
      
      
      <categories>
          
          <category> 爬虫 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 爬虫 </tag>
            
            <tag> request </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>千里之行，始于足下。python 爬虫 requestes模块（2）</title>
      <link href="/2022/11/19/qian-li-zhi-xing-shi-yu-zu-xia-python-pa-chong-requestes-mo-kuai-2/"/>
      <url>/2022/11/19/qian-li-zhi-xing-shi-yu-zu-xia-python-pa-chong-requestes-mo-kuai-2/</url>
      
        <content type="html"><![CDATA[<h1 id="简易网页搜集器"><a href="#简易网页搜集器" class="headerlink" title="简易网页搜集器"></a>简易网页搜集器</h1><p>前面我们已经学会了简单爬取浏览器页面的爬虫。但事实上我们的需求当然不是爬取搜狗首页或是B站首页这么简单，再不济，我们都希望可以爬取某个特定的有信息的页面。</p><p>不知道在学会了爬取之后，你有没有跟我一样试着去爬取一些搜索页面，比如说百度。像这样的页面</p><p><img src="https://img-blog.csdnimg.cn/20210415104803318.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70" alt="要爬取的网页"></p><p>注意我红笔划的部分，这是我打开的网页。现在我希望能爬取这一页的数据，按我们前面学的代码，应该是这样写的：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> requests<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># 指定URL</span>    url <span class="token operator">=</span> <span class="token string">"https://www.baidu.com/s?ie=utf-8&amp;f=8&amp;rsv_bp=1&amp;rsv_idx=2&amp;tn=93923645_hao_pg&amp;wd=%E5%A5%A5%E7%89%B9%E6%9B%BC&amp;rsv_spt=1&amp;oq=%25E7%2588%25AC%25E5%258F%2596%25E7%2599%25BE%25E5%25BA%25A6%25E9%25A6%2596%25E9%25A1%25B5&amp;rsv_pq=b233dcfd0002d2d8&amp;rsv_t=ccdbEuqbJfqtjnkFvevj%2BfxQ0Sj2UP88ixXHTNUNsmTa9yWEWTUEgxTta9r%2Fj3mXxDs%2BT1SU&amp;rqlang=cn&amp;rsv_dl=tb&amp;rsv_enter=1&amp;rsv_sug3=8&amp;rsv_sug1=5&amp;rsv_sug7=100&amp;rsv_sug2=0&amp;rsv_btype=t&amp;inputT=1424&amp;rsv_sug4=1424"</span>    <span class="token comment" spellcheck="true"># 发送请求</span>    response <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 获取数据</span>    page_text <span class="token operator">=</span> response<span class="token punctuation">.</span>text    <span class="token comment" spellcheck="true"># 存储</span>    <span class="token keyword">with</span> open<span class="token punctuation">(</span><span class="token string">"./奥特曼.html"</span><span class="token punctuation">,</span> <span class="token string">"w"</span><span class="token punctuation">,</span> encoding <span class="token operator">=</span> <span class="token string">"utf-8"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> fp<span class="token punctuation">:</span>        fp<span class="token punctuation">.</span>write<span class="token punctuation">(</span>page_text<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"爬取成功！！！"</span><span class="token punctuation">)</span></code></pre><p>然而打开我们保存的文件，发现结果跟我们想的不太一样<br><img src="https://img-blog.csdnimg.cn/20210415110105396.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70"><br>我们发现我们保存的文件是一个空白的页面，这是为什么呢？</p><p>其实上我们把网址改成搜狗的可能或更直观一些（不知道为什么我这边的搜狗总是打不开，所以就用百度做例子，可以自己写写有关搜狗搜索的代码），同样的代码改成搜狗的网址结果是这样的</p><p><img src="https://img-blog.csdnimg.cn/20210415110721166.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70"><br>我们发现其中有句话是 “ 网络中存在异常访问 ”，那么这句话是什么意思呢？这句话的意思就是说，搜狗或是百度注意到发送请求的是爬虫程序，而不是人工操作。</p><p>那么这其中的原理又是什么呢？简单来说，就是程序访问和我们使用浏览器访问是有区别的，被请求的服务器都是靠 user-agent 来判断访问者的身份，如果是浏览器就接受请求，否则就拒绝。这就是一个很常见的反爬机制。</p><p>那是不是我们就没有办法呢？非也~所谓魔高一尺，道高一丈。既然要识别 user-agent ，那么我们就让爬虫模拟 user-agent 好了。</p><p>在 python 中模拟输入数据或是 user-agent ，我们一般用字典<br>就这样子写：</p><pre class=" language-python"><code class="language-python">header <span class="token operator">=</span> <span class="token punctuation">{</span>    <span class="token string">"user-agent"</span><span class="token punctuation">:</span> <span class="token string">""</span> <span class="token comment" spellcheck="true"># user-agent 的值 是一个长字符串</span>    <span class="token punctuation">}</span></code></pre><p>那么  user-agent 的值又是怎么得到的呢？<br>    1. 打开任意网页，右键点击，选择“检查”<br><img src="https://img-blog.csdnimg.cn/20210415112140584.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70"><br>    2. 选择“ Network ”（谷歌浏览器）（如果是中文，就选择 “网络” 这一项）<br><img src="https://img-blog.csdnimg.cn/20210415112339671.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70"><br>    3. 如果发现点开是空白的，像这样，那就刷新网页<br>    <img src="https://img-blog.csdnimg.cn/2021041511261560.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70"><br>    刷新后是这样的：<br>    <img src="https://img-blog.csdnimg.cn/20210415112717305.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70"><br>然后随机选择红笔圈起来的一项，我们会看到这样的东西，然后在里面找到“user-agent”，把它的值复制下来就行了<br><img src="https://img-blog.csdnimg.cn/20210415113039196.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70"><br>有了 “user-agent”， 我们在重新写我们的爬取网页的代码，就可以了</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> requests<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># 指定URL</span>    url <span class="token operator">=</span> <span class="token string">"https://www.baidu.com/s?ie=utf-8&amp;f=8&amp;rsv_bp=1&amp;rsv_idx=2&amp;tn=93923645_hao_pg&amp;wd=%E5%A5%A5%E7%89%B9%E6%9B%BC&amp;rsv_spt=1&amp;oq=%25E7%2588%25AC%25E5%258F%2596%25E7%2599%25BE%25E5%25BA%25A6%25E9%25A6%2596%25E9%25A1%25B5&amp;rsv_pq=b233dcfd0002d2d8&amp;rsv_t=ccdbEuqbJfqtjnkFvevj%2BfxQ0Sj2UP88ixXHTNUNsmTa9yWEWTUEgxTta9r%2Fj3mXxDs%2BT1SU&amp;rqlang=cn&amp;rsv_dl=tb&amp;rsv_enter=1&amp;rsv_sug3=8&amp;rsv_sug1=5&amp;rsv_sug7=100&amp;rsv_sug2=0&amp;rsv_btype=t&amp;inputT=1424&amp;rsv_sug4=1424"</span>    <span class="token comment" spellcheck="true"># 模拟 “user-agent”，即 UA伪装</span>    header <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token string">"user-agent"</span> <span class="token punctuation">:</span> <span class="token string">""</span> <span class="token comment" spellcheck="true"># 复制的 user-agent 的值</span>        <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true"># 发送请求</span>    response <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">,</span> headers <span class="token operator">=</span> header<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 获取数据</span>    page_text <span class="token operator">=</span> response<span class="token punctuation">.</span>text    <span class="token comment" spellcheck="true"># 存储</span>    <span class="token keyword">with</span> open<span class="token punctuation">(</span><span class="token string">"./奥特曼(UA伪装).html"</span><span class="token punctuation">,</span> <span class="token string">"w"</span><span class="token punctuation">,</span> encoding <span class="token operator">=</span> <span class="token string">"utf-8"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> fp<span class="token punctuation">:</span>        fp<span class="token punctuation">.</span>write<span class="token punctuation">(</span>page_text<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"爬取成功！！！"</span><span class="token punctuation">)</span></code></pre><p>再次运行，然后打开文件<br><img src="https://img-blog.csdnimg.cn/20210415113826866.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70"><br>这次成功了，说明我们的爬虫程序完美地骗过了服务器</p>]]></content>
      
      
      <categories>
          
          <category> 爬虫 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 爬虫 </tag>
            
            <tag> request </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>千里之行，始于足下。python 爬虫 requestes模块（1）</title>
      <link href="/2022/11/19/qian-li-zhi-xing-shi-yu-zu-xia-python-pa-chong-requestes-mo-kuai-1/"/>
      <url>/2022/11/19/qian-li-zhi-xing-shi-yu-zu-xia-python-pa-chong-requestes-mo-kuai-1/</url>
      
        <content type="html"><![CDATA[<h1 id="爬虫的流程："><a href="#爬虫的流程：" class="headerlink" title="爬虫的流程："></a>爬虫的流程：</h1><p>在开始学习爬虫，我们必须了解爬虫的流程框架。在我看来爬虫的流程大概就是三步，即不论我们爬取的是什么数据，总是可以把爬虫的流程归纳总结为这三步：</p><ol><li>指定 url， 可以简单的理解为指定要爬取的网址</li><li>发送请求。requests 模块的请求一般为 get 和 post</li><li>将爬取的数据存储</li></ol><h1 id="requests-模块的下载导入："><a href="#requests-模块的下载导入：" class="headerlink" title="requests 模块的下载导入："></a>requests 模块的下载导入：</h1><p>因为 requests 模块属于外部库，所以需要我们自己导入库</p><p>导入的步骤：</p><ol><li>右键Windows图标</li><li>点击“运行”</li><li>输入“cmd”打开命令面板</li><li>输入“pip install requests”,等待下载完成</li></ol><p>如图：</p><p><img src="https://img-blog.csdnimg.cn/20210413165648257.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_1,color_FFFFFF,t_70"></p><p><img src="https://img-blog.csdnimg.cn/20210413165904237.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70" alt="打开cmd"></p><p><img src="https://img-blog.csdnimg.cn/20210413165910162.png" alt="下载 requests 模块 "></p><p>如果还是下载失败，我的建议是”百度一下，你就知道“（我也是边学边写，是在是水平有限）</p><p>欧克，既然导入成功后我们就简单的来爬取一下搜狗的首页吧！<br>代码如下：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> requests<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># 指定url</span>    url <span class="token operator">=</span> <span class="token string">"https://www.sougou.com/"</span>    <span class="token comment" spellcheck="true"># 发起请求</span>    <span class="token comment" spellcheck="true"># get方法会返回一个响应数据</span>    response <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 获取响应数据</span>    page_txt <span class="token operator">=</span> response<span class="token punctuation">.</span>text <span class="token comment" spellcheck="true"># text返回一个字符串的响应数据</span>    <span class="token comment" spellcheck="true"># print(page_txt)</span>    <span class="token comment" spellcheck="true"># 存储</span>    <span class="token keyword">with</span> open<span class="token punctuation">(</span><span class="token string">"./sougou.html"</span><span class="token punctuation">,</span> <span class="token string">"w"</span><span class="token punctuation">,</span> encoding <span class="token operator">=</span> <span class="token string">"utf-8"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> fp<span class="token punctuation">:</span>        fp<span class="token punctuation">.</span>write<span class="token punctuation">(</span>page_txt<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"爬取数据结束！！！"</span><span class="token punctuation">)</span></code></pre><p>我们打开保存的文件，如图<br><img src="https://img-blog.csdnimg.cn/2021041317282155.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoaUppZURlWWluWXU=,size_16,color_FFFFFF,t_70" alt="成功保存的网页"></p>]]></content>
      
      
      <categories>
          
          <category> 爬虫 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 爬虫 </tag>
            
            <tag> request </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2022/11/18/hello-world/"/>
      <url>/2022/11/18/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre class=" language-bash"><code class="language-bash">$ hexo new <span class="token string">"My New Post"</span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre class=" language-bash"><code class="language-bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre class=" language-bash"><code class="language-bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre class=" language-bash"><code class="language-bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      <categories>
          
          <category> hexo </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
